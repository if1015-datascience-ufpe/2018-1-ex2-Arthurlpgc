## Resumo 1
Texto: [Real-Time Face Recognition Threatens to Turn Cops’ Body Cameras into Surveillance Machines](https://theintercept.com/2017/03/22/real-time-face-recognition-threatens-to-turn-cops-body-cameras-into-surveillance-machines/)

O Texto informa que alguns dos investimentos crescentes em tecnologias no ramo policial incluem reconhecimento facial, e cameras no corpo dos oficiais. As cameras tem o intuito de servir de evidencia tanto para o policiais, quanto para os suspeitos, dado que ha vezes que existe abuso de poder. No futuro essas gravaçoes podem ser usadas para reconhecimento facial. Reconhecimento facial em todas as cameras de monitoramento é algo crescente, e que vai diminuir muito a privacidade dos cidadoes. Não bastasse isso, como muitas pessoas tem infracoes, pode haver abuso de poder: "ja que todos tem infraçoes, pode se so escolher os que tenho algo contra". A busca pode ser feita retroativamente, e pode se traçar todas as localizaçoes de um individuo, não so a partir do momento que se avisa que esse tipo de pratica ira começar, o que causa um medo de atos passados para os individuos, e questiona a liberdade que tem. Alem disso, esse tipo de reconhecimento não é 100% preciso, e pode acusar individuos inocentes, e causar constragimentos. Esse tipo de vigilancia pode dar errado e se der, não ha como garantir que os policiais fariam um rollback, existem casos onde metodos são falhos(camera no corpo dos policiais é raramente utilizada para acusar o policial de atirar em um suspeito, mas o oposto não é verdade) e mesmo sendo falhos, ou injustos continuam a acontecer porque de certa forma dão dinheiro ao governo, mesmo que não melhore a vida dos cidadoes. 

## Resumo 2
Texto: [How Vector Space Mathematics Reveals the Hidden Sexism in Language](https://www.technologyreview.com/s/602025/how-vector-space-mathematics-reveals-the-hidden-sexism-in-language/)

Em 2013, alguns pesquisadores do google rodaram uma rede neural num corpus de 3e6 palavras tiradas do Google News. A motivação da pesquisa era buscar padrōes na frequencia em que palavras apareciam juntas. Essa rede neural gerou um espaço vetorial com aproximadamente 300 dimensões, onde as palavras com sentidos similares, aparecem em areas similares do espaço, e se consegue ver correlação entre palavras, da para inferir que tokyo esta para japāo, assim como paris esta para frança. Esse Dataset é conhecido como Word2Vec, e é bastante usado em traduçōes.

Pesquisadores da universidade de Boston e da Microsoft Research descobriram que os dados do Word2Vec uma vez que refletem as opiniões da sociedade, são sexistas, e que coisas como pai esta para medico assim como mãe esta para enfermeira acontecem frequentemente.

Sexismo é representado como uma deformaçao nesse espaço, e para consertar bastar aplicar a deformaçao contraria. No entanto, essa transformaçao deve preservar as relaçoes existentes como o exemplo da relaçao entre tokyo e japão. Eles tentaram usar uma tecnica chamada Hard Debiasing para tirar esse bias no espaço vetorial do Word2Vec. Para verificar, eles usaram de pessoas no Amazon Mecanical Turk, e para cada relaçao entre palavras, 10 pessoas verificavam, se mais da metade achasse sexista, eles consideravam que era sexista, e rodaram apos o debiasing, confirmando assim que significativamente menos relacoes eram sexistas.

Mas isso gera a pergunta, se esse bias existe na sociedade, deviamos tirar o bias no texto? Isso causaria um espaco que não reflete a realidade da sociedade, que bem isso traria? e que mal? Essa duvida existe ja que para certas previsōes o debias atrapalharia, mas ao mesmo tempo esse bias pode influenciar as pessoas a ter ainda mais bias.

